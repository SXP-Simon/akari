import discord
from discord.ext import commands, tasks
import aiohttp
import time
import re
import json
import os
from dataclasses import dataclass
from typing import List, Dict, Optional, Union
from bs4 import BeautifulSoup
from lxml import etree
from urllib.parse import urlparse
import logging
from datetime import datetime
import asyncio
import traceback
from ..bot.utils import EmbedBuilder

# =====================
# akari.plugins.rss_plugin
# =====================

"""
RssPlugin: RSS è®¢é˜…ä¸æ¨é€æ’ä»¶

- æ”¯æŒ RSS æºè®¢é˜…ã€ç®¡ç†ä¸æ¨é€
- Discord å‘½ä»¤é›†æˆ
- æ•°æ®æŒä¹…åŒ–ä¸å®šæ—¶ä»»åŠ¡

Attributes:
    bot (commands.Bot): å…³è”çš„ Bot å®ä¾‹
    ...
"""

@dataclass
class RSSConfig:
    """RSSé…ç½®"""
    title_max_length: int = 30
    description_max_length: int = 500
    max_items_per_poll: int = 3
    check_interval: int = 5
    is_hide_url: bool = False
    pic_config: Dict[str, Union[bool, int]] = None

    def __post_init__(self):
        if self.pic_config is None:
            self.pic_config = {
                "is_read_pic": True,
                "is_adjust_pic": False,
                "max_pic_item": 3
            }

@dataclass
class RSSItem:
    chan_title: str
    title: str
    link: str
    description: str
    pubDate: str
    pubDate_timestamp: int
    pic_urls: List[str]

    def __str__(self):
        return f"{self.title} - {self.link} - {self.description} - {self.pubDate}"

class RSSError(Exception):
    """RSSé”™è¯¯åŸºç±»"""
    pass

class RSSNetworkError(RSSError):
    """RSSç½‘ç»œé”™è¯¯"""
    pass

class RSSParseError(RSSError):
    """RSSè§£æé”™è¯¯"""
    pass

class RSSFeed:
    def __init__(self, url: str, channel_id: int, cron_expr: str = "*/5 * * * *"):
        self.url = url
        self.channel_id = channel_id
        self.cron_expr = cron_expr
        self.last_update = int(time.time())
        self.latest_link = ""
        self.error_count = 0
        self.last_error = None
        self.last_success = int(time.time())

class RSSManager:
    def __init__(self, config_path: str = "data/rss/rss_data.json"):
        self.config_path = config_path
        self.feeds = {}
        self.load_data()

    def load_data(self):
        """ä»æ•°æ®æ–‡ä»¶ä¸­åŠ è½½æ•°æ®"""
        if not os.path.exists(self.config_path):
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            self.save_data()
            return

        try:
            with open(self.config_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                for url, info in data.items():
                    if url == "settings":
                        continue
                    self.feeds[url] = {}
                    for channel_id, feed_data in info.get("subscribers", {}).items():
                        channel_id = int(channel_id)
                        self.feeds[url][channel_id] = RSSFeed(
                            url=url,
                            channel_id=channel_id,
                            cron_expr=feed_data.get("cron_expr", "*/5 * * * *")
                        )
                        self.feeds[url][channel_id].last_update = feed_data.get("last_update", int(time.time()))
                        self.feeds[url][channel_id].latest_link = feed_data.get("latest_link", "")
                        self.feeds[url][channel_id].error_count = feed_data.get("error_count", 0)
                        self.feeds[url][channel_id].last_error = feed_data.get("last_error")
                        self.feeds[url][channel_id].last_success = feed_data.get("last_success", int(time.time()))
        except Exception as e:
            logging.error(f"åŠ è½½RSSæ•°æ®å¤±è´¥: {str(e)}")
            self.feeds = {}

    def save_data(self):
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®æ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            data = {}
            for url, channels in self.feeds.items():
                data[url] = {
                    "subscribers": {},
                    "info": {}  # ç”¨äºå­˜å‚¨é¢‘é“ä¿¡æ¯
                }
                for channel_id, feed in channels.items():
                    data[url]["subscribers"][str(channel_id)] = {
                        "cron_expr": feed.cron_expr,
                        "last_update": feed.last_update,
                        "latest_link": feed.latest_link,
                        "error_count": feed.error_count,
                        "last_error": feed.last_error,
                        "last_success": feed.last_success
                    }
            
            with open(self.config_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logging.error(f"ä¿å­˜RSSæ•°æ®å¤±è´¥: {str(e)}")

    def add_feed(self, url: str, channel_id: int, cron_expr: str) -> bool:
        """æ·»åŠ æ–°çš„è®¢é˜…"""
        if url not in self.feeds:
            self.feeds[url] = {}
        
        if channel_id in self.feeds[url]:
            return False
        
        self.feeds[url][channel_id] = RSSFeed(url, channel_id, cron_expr)
        self.save_data()
        return True

    def remove_feed(self, url: str, channel_id: int) -> bool:
        """ç§»é™¤è®¢é˜…"""
        if url not in self.feeds or channel_id not in self.feeds[url]:
            return False
        
        del self.feeds[url][channel_id]
        if not self.feeds[url]:
            del self.feeds[url]
        self.save_data()
        return True

    def get_channel_feeds(self, channel_id: int) -> List[RSSFeed]:
        """è·å–é¢‘é“çš„æ‰€æœ‰è®¢é˜…"""
        result = []
        for url, channels in self.feeds.items():
            if channel_id in channels:
                result.append(channels[channel_id])
        return result

class RSS(commands.Cog):
    """RSSè®¢é˜…æ’ä»¶"""
    def __init__(self, bot):
        self.bot = bot
        self.logger = logging.getLogger(f"discord.{self.__class__.__name__}")
        self.config_path = "data/rss/rss_config.json"
        self.rss_manager = RSSManager()
        
        # åŠ è½½æˆ–åˆ›å»ºé»˜è®¤é…ç½®
        self.config = self._load_or_create_config()
        
        # åˆ›å»ºRSSæ£€æŸ¥ä»»åŠ¡
        self._setup_rss_task()

    def _load_or_create_config(self):
        """åŠ è½½æˆ–åˆ›å»ºé»˜è®¤é…ç½®"""
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return RSSConfig(
                        title_max_length=data.get("title_max_length", 30),
                        description_max_length=data.get("description_max_length", 500),
                        max_items_per_poll=data.get("max_items_per_poll", 3),
                        check_interval=data.get("check_interval", 5),
                        is_hide_url=data.get("is_hide_url", False),
                        pic_config=data.get("pic_config", None)
                    )
            else:
                config = RSSConfig()
                self._save_config(config)
                return config
        except Exception as e:
            self.logger.error(f"åŠ è½½RSSé…ç½®å¤±è´¥: {str(e)}")
            return RSSConfig()

    def _save_config(self, config: RSSConfig):
        """ä¿å­˜é…ç½®"""
        try:
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            data = {
                "title_max_length": config.title_max_length,
                "description_max_length": config.description_max_length,
                "max_items_per_poll": config.max_items_per_poll,
                "check_interval": config.check_interval,
                "is_hide_url": config.is_hide_url,
                "pic_config": config.pic_config
            }
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"ä¿å­˜RSSé…ç½®å¤±è´¥: {str(e)}")

    def _setup_rss_task(self):
        """è®¾ç½®RSSæ£€æŸ¥ä»»åŠ¡"""
        interval = self.config.check_interval
        
        @tasks.loop(minutes=interval)
        async def check_rss_updates():
            """å®šæœŸæ£€æŸ¥RSSæ›´æ–°"""
            for url, channels in self.rss_manager.feeds.items():
                for channel_id, feed in channels.items():
                    try:
                        channel = self.bot.get_channel(channel_id)
                        if not channel:
                            self.logger.warning(f"æ‰¾ä¸åˆ°é¢‘é“ {channel_id}ï¼Œè·³è¿‡RSSæ£€æŸ¥: {url}")
                            continue

                        items = await self.fetch_rss_items(
                            url,
                            after_timestamp=feed.last_update,
                            after_link=feed.latest_link
                        )

                        if not items:
                            continue

                        for item in items:
                            embed = await self._create_rss_embed(item)
                            try:
                                await channel.send(embed=embed)
                            except discord.HTTPException as e:
                                self.logger.error(f"å‘é€RSSæ¶ˆæ¯å¤±è´¥ {url} -> {channel_id}: {str(e)}")
                                continue

                        feed.last_update = max(feed.last_update, max((item.pubDate_timestamp for item in items), default=feed.last_update))
                        if items:
                            feed.latest_link = items[0].link
                        
                        # æ›´æ–°æˆåŠŸçŠ¶æ€
                        feed.error_count = 0
                        feed.last_error = None
                        feed.last_success = int(time.time())
                        self.rss_manager.save_data()

                    except Exception as e:
                        feed.error_count += 1
                        feed.last_error = f"{str(e)}\n{traceback.format_exc()}"
                        self.logger.error(f"æ£€æŸ¥RSSæ›´æ–°å¤±è´¥ {url} -> {channel_id}: {str(e)}\n{traceback.format_exc()}")
                        self.rss_manager.save_data()

                        # å¦‚æœè¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œå‘é€è­¦å‘Š
                        if feed.error_count >= 3:
                            try:
                                embed = EmbedBuilder.error(
                                    title="RSSè®¢é˜…å¼‚å¸¸",
                                    description=f"è®¢é˜…æº `{url}` å·²è¿ç»­ {feed.error_count} æ¬¡æ›´æ–°å¤±è´¥\n"
                                              f"æœ€åä¸€æ¬¡é”™è¯¯: {str(e)}\n"
                                              f"å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œå»ºè®®ä½¿ç”¨ `!rss remove {url}` å–æ¶ˆè®¢é˜…"
                                )
                                await channel.send(embed=embed)
                            except:
                                pass

        @check_rss_updates.before_loop
        async def before_check():
            await self.bot.wait_until_ready()

        self.check_rss_updates = check_rss_updates
        self.check_rss_updates.start()

    async def _create_rss_embed(self, item: RSSItem) -> discord.Embed:
        """åˆ›å»ºRSSæ¶ˆæ¯çš„Embed"""
        description = item.description
        if len(description) > self.config.description_max_length:
            description = description[:self.config.description_max_length] + "..."

        # æ·»åŠ RSSæºåç§°ä½œä¸ºå‰ç¼€
        title_prefix = f"[{item.chan_title}] " if item.chan_title else ""
        title = title_prefix + item.title[:self.config.title_max_length]

        embed = EmbedBuilder.info(
            title=title,
            description=description
        )

        if not self.config.is_hide_url:
            embed.url = item.link

        embed.timestamp = datetime.fromtimestamp(item.pubDate_timestamp) if item.pubDate_timestamp else discord.utils.utcnow()
        
        if item.pic_urls and self.config.pic_config["is_read_pic"]:
            max_pics = self.config.pic_config["max_pic_item"]
            for i, pic_url in enumerate(item.pic_urls[:max_pics]):
                if i == 0:
                    embed.set_image(url=pic_url)
                else:
                    # å¯¹äºé¢å¤–çš„å›¾ç‰‡ï¼Œæ·»åŠ åˆ°å­—æ®µä¸­
                    embed.add_field(name=f"é™„å›¾ {i+1}", value=pic_url, inline=False)

        return embed

    def cog_unload(self):
        """æ’ä»¶å¸è½½æ—¶çš„æ¸…ç†å·¥ä½œ"""
        if self.check_rss_updates.is_running():
            self.check_rss_updates.cancel()

    async def parse_rss_feed(self, url: str) -> Optional[tuple[str, str]]:
        """è§£æRSSé¢‘é“ä¿¡æ¯"""
        try:
            async with aiohttp.ClientSession(trust_env=True) as session:
                async with session.get(url) as resp:
                    if resp.status != 200:
                        return None
                    text = await resp.text()
                    root = etree.fromstring(text.encode('utf-8'))
                    nsmap = root.nsmap.copy() if hasattr(root, 'nsmap') else {}
                    if None in nsmap:
                        nsmap['atom'] = nsmap.pop(None)
                    # å°è¯•ä¸åŒçš„ XPath è·¯å¾„æ¥æŸ¥æ‰¾æ ‡é¢˜å’Œæè¿°ï¼Œä¼˜å…ˆè€ƒè™‘å‘½åç©ºé—´
                    title = None
                    description = None
                    # æ ‡é¢˜
                    for path in ["//channel/title", "//feed/title", "//atom:title", "//title"]:
                        elements = root.xpath(path, namespaces=nsmap) if 'atom' in path else root.xpath(path)
                        if elements and getattr(elements[0], 'text', None):
                            title = elements[0].text.strip()
                            break
                    # æè¿°
                    for path in ["//channel/description", "//feed/subtitle", "//feed/description", "//atom:subtitle", "//description"]:
                        elements = root.xpath(path, namespaces=nsmap) if 'atom' in path else root.xpath(path)
                        if elements and getattr(elements[0], 'text', None):
                            description = elements[0].text.strip()
                            break
                    if not title:
                        title = "æœªçŸ¥é¢‘é“"
                    if not description:
                        description = "æ— æè¿°"
                    return title, description
        except Exception as e:
            self.logger.error(f"è§£æRSSé¢‘é“å¤±è´¥: {url} - {str(e)}")
            return None

    async def fetch_rss_items(
        self,
        url: str,
        after_timestamp: int = 0,
        after_link: str = "",
        num: int = None
    ) -> List[RSSItem]:
        """ä»ç«™ç‚¹æ‹‰å–RSSä¿¡æ¯ï¼Œè‡ªåŠ¨å…¼å®¹RSSä¸Atomæ ¼å¼"""
        try:
            async with aiohttp.ClientSession(trust_env=True) as session:
                async with session.get(url) as resp:
                    if resp.status != 200:
                        self.logger.error(f"æ— æ³•è·å–RSSå†…å®¹: {url}")
                        return []
                    text = await resp.text()
                    root = etree.fromstring(text.encode('utf-8'))
                    nsmap = root.nsmap.copy() if hasattr(root, 'nsmap') else {}
                    if None in nsmap:
                        nsmap['atom'] = nsmap.pop(None)
                    # 1. æ”¯æŒAtom //entry
                    items = root.xpath("//item")
                    is_atom = False
                    if not items:
                        items = root.xpath("//atom:entry", namespaces=nsmap)
                        is_atom = True if items else False
                    if not items:
                        items = root.xpath("//entry")
                        is_atom = True if items else is_atom
                    if not items:
                        self.logger.error(f"æœªæ‰¾åˆ°RSS/Atomæ¡ç›®: {url}")
                        return []
                    max_items = num if num is not None else self.config.max_items_per_poll
                    rss_items = []
                    for item in items:
                        try:
                            # æ ‡é¢˜
                            title = None
                            for title_path in (["title", ".//title"] if not is_atom else ["atom:title", "title"]):
                                title_elements = item.xpath(title_path, namespaces=nsmap) if 'atom' in title_path else item.xpath(title_path)
                                if title_elements and (getattr(title_elements[0], 'text', None) or isinstance(title_elements[0], str)):
                                    title = title_elements[0].text.strip() if hasattr(title_elements[0], 'text') and title_elements[0].text else str(title_elements[0]).strip()
                                    break
                            if not title:
                                continue
                            if len(title) > self.config.title_max_length:
                                title = title[:self.config.title_max_length] + "..."
                            # é“¾æ¥
                            link = None
                            if not is_atom:
                                for link_path in ["link", ".//link", ".//link/@href"]:
                                    link_elements = item.xpath(link_path)
                                    if link_elements:
                                        link = link_elements[0] if isinstance(link_elements[0], str) else link_elements[0].text
                                        if link:
                                            link = link.strip()
                                            break
                            else:
                                link_elements = item.xpath("atom:link/@href", namespaces=nsmap)
                                if not link_elements:
                                    link_elements = item.xpath("link/@href")
                                if link_elements:
                                    link = link_elements[0].strip()
                                else:
                                    link_elements = item.xpath("atom:link", namespaces=nsmap)
                                    if not link_elements:
                                        link_elements = item.xpath("link")
                                    if link_elements and hasattr(link_elements[0], 'text') and link_elements[0].text:
                                        link = link_elements[0].text.strip()
                            if not link:
                                continue
                            if not re.match(r"^https?://", link):
                                link = self.get_root_url(url) + link
                            # æè¿°
                            description = None
                            if not is_atom:
                                for desc_path in ["description", ".//description", "content", ".//content", "summary", ".//summary"]:
                                    desc_elements = item.xpath(desc_path)
                                    if desc_elements and getattr(desc_elements[0], 'text', None):
                                        description = desc_elements[0].text
                                        break
                            else:
                                for desc_path in ["atom:summary", "atom:content", "summary", "content"]:
                                    desc_elements = item.xpath(desc_path, namespaces=nsmap) if 'atom' in desc_path else item.xpath(desc_path)
                                    if desc_elements and (getattr(desc_elements[0], 'text', None) or isinstance(desc_elements[0], str)):
                                        description = desc_elements[0].text if hasattr(desc_elements[0], 'text') and desc_elements[0].text else str(desc_elements[0])
                                        break
                            if not description:
                                description = "æ— æè¿°"
                            pic_urls = self.extract_images(description)
                            description = self.strip_html(description)
                            if len(description) > self.config.description_max_length:
                                description = description[:self.config.description_max_length] + "..."
                            # é¢‘é“æ ‡é¢˜
                            chan_title = ""
                            for chan_title_path in ["//channel/title", "//feed/title", "//atom:title"]:
                                chan_elements = root.xpath(chan_title_path, namespaces=nsmap) if 'atom' in chan_title_path else root.xpath(chan_title_path)
                                if chan_elements and getattr(chan_elements[0], 'text', None):
                                    chan_title = chan_elements[0].text.strip()
                                    break
                            # æ—¶é—´
                            pub_date = ""
                            pub_date_timestamp = 0
                            if not is_atom:
                                date_paths = ["pubDate", ".//pubDate", "published", ".//published", "updated", ".//updated"]
                            else:
                                date_paths = ["atom:updated", "atom:published", "updated", "published"]
                            for date_path in date_paths:
                                date_elements = item.xpath(date_path, namespaces=nsmap) if 'atom' in date_path else item.xpath(date_path)
                                if date_elements and (getattr(date_elements[0], 'text', None) or isinstance(date_elements[0], str)):
                                    pub_date = date_elements[0].text.strip() if hasattr(date_elements[0], 'text') and date_elements[0].text else str(date_elements[0]).strip()
                                    try:
                                        date_formats = [
                                            "%a, %d %b %Y %H:%M:%S %z",
                                            "%Y-%m-%dT%H:%M:%S%z",
                                            "%Y-%m-%dT%H:%M:%SZ",
                                            "%Y-%m-%d %H:%M:%S"
                                        ]
                                        for date_format in date_formats:
                                            try:
                                                dt = pub_date
                                                if "GMT" in dt:
                                                    dt = dt.replace("GMT", "+0000")
                                                if "Z" in dt:
                                                    dt = dt.replace("Z", "+0000")
                                                pub_date_parsed = time.strptime(dt, date_format)
                                                pub_date_timestamp = int(time.mktime(pub_date_parsed))
                                                break
                                            except ValueError:
                                                continue
                                        if pub_date_timestamp == 0:
                                            pub_date_timestamp = int(time.time())
                                        break
                                    except:
                                        pub_date_timestamp = int(time.time())
                                    break
                            if pub_date_timestamp > after_timestamp or (pub_date_timestamp == 0 and link != after_link):
                                rss_items.append(
                                    RSSItem(
                                        chan_title=chan_title,
                                        title=title,
                                        link=link,
                                        description=description,
                                        pubDate=pub_date,
                                        pubDate_timestamp=pub_date_timestamp,
                                        pic_urls=pic_urls
                                    )
                                )
                                if max_items > 0 and len(rss_items) >= max_items:
                                    break
                            else:
                                break
                        except Exception as e:
                            self.logger.error(f"è§£æRSS/Atomæ¡ç›®å¤±è´¥: {url} - {str(e)}")
                            continue
                    return rss_items
        except Exception as e:
            self.logger.error(f"è·å–RSSå†…å®¹å¤±è´¥: {url} - {str(e)}\n{traceback.format_exc()}")
            return []

    def strip_html(self, html: str) -> str:
        """ç§»é™¤HTMLæ ‡ç­¾"""
        soup = BeautifulSoup(html, "html.parser")
        text = soup.get_text()
        return re.sub(r"\n+", "\n", text)

    def extract_images(self, html: str) -> List[str]:
        """æå–HTMLä¸­çš„å›¾ç‰‡URL"""
        soup = BeautifulSoup(html, "html.parser")
        return [img.get('src') for img in soup.find_all('img') if img.get('src')]

    def get_root_url(self, url: str) -> str:
        """è·å–URLçš„æ ¹åŸŸå"""
        parsed_url = urlparse(url)
        return f"{parsed_url.scheme}://{parsed_url.netloc}"

    @commands.group(name="rss", invoke_without_command=True)
    async def rss(self, ctx):
        """RSSè®¢é˜…ç®¡ç†"""
        if ctx.invoked_subcommand is None:
            commands = {
                "!rss add <url> [cron]": "æ·»åŠ RSSè®¢é˜…ï¼Œå¯é€‰æŒ‡å®šæ£€æŸ¥é—´éš”",
                "!rss remove <url>": "ç§»é™¤RSSè®¢é˜…",
                "!rss list": "æŸ¥çœ‹å½“å‰é¢‘é“çš„RSSè®¢é˜…åˆ—è¡¨",
                "!rss info <url>": "æŸ¥çœ‹RSSè®¢é˜…è¯¦ç»†ä¿¡æ¯",
                "!rss test <url>": "æµ‹è¯•RSSè®¢é˜…æº",
                "!rss config": "æŸ¥çœ‹å’Œä¿®æ”¹RSSé…ç½®"
            }
            await ctx.send(embed=EmbedBuilder.menu(
                title="RSSè®¢é˜…ç®¡ç†",
                description="ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç®¡ç†RSSè®¢é˜…ï¼š",
                commands=commands
            ))

    @rss.command(name="add")
    async def add_feed(self, ctx, url: str, cron: str = "*/5 * * * *"):
        """æ·»åŠ RSSè®¢é˜…
        ç”¨æ³•ï¼š!rss add <url> [cronè¡¨è¾¾å¼]
        ä¾‹å¦‚ï¼š!rss add https://rsshub.app/cngal/weekly
        """
        try:
            # æµ‹è¯•RSSæºæ˜¯å¦å¯ç”¨
            feed_info = await self.parse_rss_feed(url)
            if not feed_info:
                await ctx.send(embed=EmbedBuilder.error(
                    title="æ·»åŠ å¤±è´¥",
                    description="æ— æ³•è·å–RSSæºä¿¡æ¯ï¼Œè¯·æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®"
                ))
                return

            title, description = feed_info
            if self.rss_manager.add_feed(url, ctx.channel.id, cron):
                embed = EmbedBuilder.success(
                    title="RSSè®¢é˜…æ·»åŠ æˆåŠŸ",
                    description=f"**é¢‘é“:** {title}\n**æè¿°:** {description}\n**æ£€æŸ¥é—´éš”:** {cron}"
                )
                # æ·»åŠ æµ‹è¯•è·å–
                try:
                    items = await self.fetch_rss_items(url, num=1)
                    if items:
                        embed.add_field(
                            name="æœ€æ–°æ–‡ç« ",
                            value=f"**{items[0].title}**\n{items[0].description[:100]}...",
                            inline=False
                        )
                except Exception as e:
                    embed.add_field(
                        name="è­¦å‘Š",
                        value=f"è·å–æœ€æ–°æ–‡ç« å¤±è´¥: {str(e)}",
                        inline=False
                    )
                await ctx.send(embed=embed)
            else:
                await ctx.send(embed=EmbedBuilder.warning(
                    title="æ·»åŠ å¤±è´¥",
                    description="è¯¥RSSæºå·²ç»è®¢é˜…"
                ))
        except Exception as e:
            await ctx.send(embed=EmbedBuilder.error(
                title="æ·»åŠ å¤±è´¥",
                description=f"å‘ç”Ÿé”™è¯¯: {str(e)}"
            ))

    @rss.command(name="remove")
    async def remove_feed(self, ctx, url: str):
        """ç§»é™¤RSSè®¢é˜…
        ç”¨æ³•ï¼š!rss remove <url>
        ä¾‹å¦‚ï¼š!rss remove https://rsshub.app/cngal/weekly
        """
        if self.rss_manager.remove_feed(url, ctx.channel.id):
            await ctx.send(embed=EmbedBuilder.success(
                title="RSSè®¢é˜…å·²ç§»é™¤"
            ))
        else:
            await ctx.send(embed=EmbedBuilder.error(
                title="ç§»é™¤å¤±è´¥",
                description="æœªæ‰¾åˆ°è¯¥RSSè®¢é˜…"
            ))

    @rss.command(name="list")
    async def list_feeds(self, ctx):
        """åˆ—å‡ºå½“å‰é¢‘é“çš„RSSè®¢é˜…
        ç”¨æ³•ï¼š!rss list
        """
        feeds = self.rss_manager.get_channel_feeds(ctx.channel.id)
        if not feeds:
            await ctx.send(embed=EmbedBuilder.info(
                title="RSSè®¢é˜…åˆ—è¡¨",
                description="ğŸ“­ å½“å‰é¢‘é“æ²¡æœ‰RSSè®¢é˜…"
            ))
            return

        fields = []
        for feed in feeds:
            feed_info = await self.parse_rss_feed(feed.url)
            title = feed_info[0] if feed_info else "æœªçŸ¥é¢‘é“"
            
            status = "âœ… æ­£å¸¸"
            if feed.error_count > 0:
                status = f"âš ï¸ å¼‚å¸¸ ({feed.error_count}æ¬¡å¤±è´¥)"
            
            field_value = (
                f"**URL:** {feed.url}\n"
                f"**æ›´æ–°é—´éš”:** {feed.cron_expr}\n"
                f"**çŠ¶æ€:** {status}\n"
                f"**æœ€åæ›´æ–°:** <t:{feed.last_update}:R>"
            )
            
            if feed.last_error:
                field_value += f"\n**æœ€åé”™è¯¯:** ```{feed.last_error[:200]}...```" if len(feed.last_error) > 200 else f"\n**æœ€åé”™è¯¯:** ```{feed.last_error}```"
            
            fields.append((title, field_value, False))

        embed = EmbedBuilder.stats(
            title="RSSè®¢é˜…åˆ—è¡¨",
            description=f"å½“å‰é¢‘é“å…±æœ‰ {len(feeds)} ä¸ªè®¢é˜…ï¼š",
            author=ctx.author
        )
        
        # é€ä¸ªæ·»åŠ å­—æ®µ
        for name, value, inline in fields:
            embed.add_field(name=name, value=value, inline=inline)
            
        await ctx.send(embed=embed)

    @rss.command(name="info")
    async def feed_info(self, ctx, url: str):
        """æŸ¥çœ‹RSSè®¢é˜…è¯¦ç»†ä¿¡æ¯
        ç”¨æ³•ï¼š!rss info <url>
        ä¾‹å¦‚ï¼š!rss info https://rsshub.app/cngal/weekly
        """
        feed = None
        for channel_feeds in self.rss_manager.feeds.get(url, {}).values():
            feed = channel_feeds
            break

        if not feed:
            await ctx.send(embed=EmbedBuilder.error(
                title="è·å–å¤±è´¥",
                description="æœªæ‰¾åˆ°è¯¥RSSè®¢é˜…"
            ))
            return

        try:
            items = await self.fetch_rss_items(url, num=3)
            feed_info = await self.parse_rss_feed(url)
            
            embed = EmbedBuilder.info(
                title=feed_info[0] if feed_info else "RSSè®¢é˜…ä¿¡æ¯",
                description=feed_info[1] if feed_info else "æ— æè¿°"
            )
            
            # æ·»åŠ åŸºæœ¬ä¿¡æ¯
            embed.add_field(
                name="åŸºæœ¬ä¿¡æ¯",
                value=(
                    f"**URL:** {url}\n"
                    f"**æ›´æ–°é—´éš”:** {feed.cron_expr}\n"
                    f"**æœ€åæ›´æ–°:** <t:{feed.last_update}:R>\n"
                    f"**çŠ¶æ€:** {'âœ… æ­£å¸¸' if feed.error_count == 0 else f'âš ï¸ å¼‚å¸¸ ({feed.error_count}æ¬¡å¤±è´¥)'}"
                ),
                inline=False
            )
            
            # æ·»åŠ æœ€æ–°æ–‡ç« ï¼ˆå¸¦é“¾æ¥ï¼‰
            if items:
                latest_items = "\n\n".join(
                    f"**[{item.title}]({item.link})**\n{item.description[:100]}..." 
                    for item in items
                )
                embed.add_field(
                    name="æœ€æ–°æ–‡ç« ",
                    value=latest_items,
                    inline=False
                )
            
            # æ·»åŠ é”™è¯¯ä¿¡æ¯
            if feed.last_error:
                embed.add_field(
                    name="æœ€åé”™è¯¯ä¿¡æ¯",
                    value=f"```{feed.last_error[:500]}...```" if len(feed.last_error) > 500 else f"```{feed.last_error}```",
                    inline=False
                )
            
            await ctx.send(embed=embed)
            
        except Exception as e:
            await ctx.send(embed=EmbedBuilder.error(
                title="è·å–å¤±è´¥",
                description=f"è·å–RSSä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            ))

    @rss.command(name="test")
    async def test_feed(self, ctx, url: str):
        """æµ‹è¯•RSSè®¢é˜…æº
        ç”¨æ³•ï¼š!rss test <url>
        ä¾‹å¦‚ï¼š!rss test https://rsshub.app/cngal/weekly
        """
        try:
            feed_info = await self.parse_rss_feed(url)
            if not feed_info:
                await ctx.send(embed=EmbedBuilder.error(
                    title="æµ‹è¯•å¤±è´¥",
                    description="æ— æ³•è·å–RSSæºä¿¡æ¯ï¼Œè¯·æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®"
                ))
                return

            title, description = feed_info
            items = await self.fetch_rss_items(url, num=3)
            
            embed = EmbedBuilder.success(
                title="RSSæºæµ‹è¯•æˆåŠŸ",
                description=f"**é¢‘é“:** {title}\n**æè¿°:** {description}"
            )
            
            if items:
                latest_items = "\n\n".join(
                    f"**[{item.title}]({item.link})**\n{item.description[:100]}..." 
                    for item in items
                )
                embed.add_field(
                    name="æœ€æ–°æ–‡ç« ",
                    value=latest_items,
                    inline=False
                )
            
            await ctx.send(embed=embed)
            
        except Exception as e:
            await ctx.send(embed=EmbedBuilder.error(
                title="æµ‹è¯•å¤±è´¥",
                description=f"æµ‹è¯•RSSæºæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            ))

    @rss.group(name="config")
    @commands.has_permissions(administrator=True)
    async def rss_config(self, ctx):
        """RSSé…ç½®ç®¡ç†ï¼ˆéœ€è¦ç®¡ç†å‘˜æƒé™ï¼‰
        ç”¨æ³•ï¼š!rss config
        """
        if ctx.invoked_subcommand is None:
            current_config = {
                "æ£€æŸ¥é—´éš”": f"{self.config.check_interval} åˆ†é’Ÿ",
                "æ ‡é¢˜æœ€å¤§é•¿åº¦": f"{self.config.title_max_length} å­—ç¬¦",
                "æè¿°æœ€å¤§é•¿åº¦": f"{self.config.description_max_length} å­—ç¬¦",
                "å•æ¬¡è·å–æœ€å¤§æ¡ç›®æ•°": str(self.config.max_items_per_poll),
                "éšè—é“¾æ¥": str(self.config.is_hide_url),
                "å›¾ç‰‡è®¾ç½®": (
                    f"è¯»å–å›¾ç‰‡: {self.config.pic_config['is_read_pic']}\n"
                    f"é˜²å’Œè°å¤„ç†: {self.config.pic_config['is_adjust_pic']}\n"
                    f"æœ€å¤§å›¾ç‰‡æ•°: {self.config.pic_config['max_pic_item']}"
                )
            }
            
            fields = [(k, v, True) for k, v in current_config.items()]
            await ctx.send(embed=EmbedBuilder.info(
                title="RSS å½“å‰é…ç½®",
                description="ä½¿ç”¨ `!rss config set <é…ç½®é¡¹> <å€¼>` ä¿®æ”¹é…ç½®",
                fields=fields
            ))

    @rss_config.command(name="set")
    async def set_config(self, ctx, key: str, value: str):
        """è®¾ç½®RSSé…ç½®é¡¹
        ç”¨æ³•ï¼š!rss config set <é…ç½®é¡¹> <å€¼>
        ä¾‹å¦‚ï¼š!rss config set check_interval 10
        """
        key = key.lower()
        try:
            if key == "check_interval":
                interval = int(value)
                if interval < 1:
                    raise ValueError("æ£€æŸ¥é—´éš”å¿…é¡»å¤§äº0")
                
                # æ›´æ–°é…ç½®
                self.config.check_interval = interval
                self._save_config(self.config)
                
                # é‡æ–°åˆ›å»ºä»»åŠ¡
                if self.check_rss_updates.is_running():
                    self.check_rss_updates.cancel()
                self._setup_rss_task()
                
                await ctx.send(embed=EmbedBuilder.success(
                    title="æ›´æ–°æˆåŠŸ",
                    description=f"RSSæ£€æŸ¥é—´éš”å·²æ›´æ–°ä¸º {interval} åˆ†é’Ÿ"
                ))
            elif key in ["title_max_length", "description_max_length", "max_items_per_poll"]:
                val = int(value)
                if val < 1:
                    raise ValueError(f"{key} å¿…é¡»å¤§äº0")
                setattr(self.config, key, val)
                self._save_config(self.config)
                await ctx.send(embed=EmbedBuilder.success(
                    title="æ›´æ–°æˆåŠŸ",
                    description=f"{key} å·²æ›´æ–°ä¸º {val}"
                ))
            elif key == "is_hide_url":
                val = value.lower() in ["true", "1", "yes", "y"]
                self.config.is_hide_url = val
                self._save_config(self.config)
                await ctx.send(embed=EmbedBuilder.success(
                    title="æ›´æ–°æˆåŠŸ",
                    description=f"éšè—é“¾æ¥å·²{'å¼€å¯' if val else 'å…³é—­'}"
                ))
            elif key.startswith("pic_"):
                pic_key = key[4:]  # ç§»é™¤ "pic_" å‰ç¼€
                if pic_key not in self.config.pic_config:
                    raise ValueError(f"æ— æ•ˆçš„å›¾ç‰‡é…ç½®é¡¹: {pic_key}")
                
                if pic_key in ["is_read_pic", "is_adjust_pic"]:
                    val = value.lower() in ["true", "1", "yes", "y"]
                else:  # max_pic_item
                    val = int(value)
                    if val < 1:
                        raise ValueError("æœ€å¤§å›¾ç‰‡æ•°å¿…é¡»å¤§äº0")
                
                self.config.pic_config[pic_key] = val
                self._save_config(self.config)
                await ctx.send(embed=EmbedBuilder.success(
                    title="æ›´æ–°æˆåŠŸ",
                    description=f"å›¾ç‰‡é…ç½® {pic_key} å·²æ›´æ–°ä¸º {val}"
                ))
            else:
                await ctx.send(embed=EmbedBuilder.error(
                    title="æ— æ•ˆçš„é…ç½®é¡¹",
                    description=(
                        "å¯ç”¨çš„é…ç½®é¡¹ï¼š\n"
                        "- check_interval\n"
                        "- title_max_length\n"
                        "- description_max_length\n"
                        "- max_items_per_poll\n"
                        "- is_hide_url\n"
                        "- pic_is_read_pic\n"
                        "- pic_is_adjust_pic\n"
                        "- pic_max_pic_item"
                    )
                ))
        except ValueError as e:
            await ctx.send(embed=EmbedBuilder.error(
                title="é…ç½®æ›´æ–°å¤±è´¥",
                description=str(e)
            ))
        except Exception as e:
            await ctx.send(embed=EmbedBuilder.error(
                title="é…ç½®æ›´æ–°å¤±è´¥",
                description=f"å‘ç”Ÿé”™è¯¯: {str(e)}"
            ))

async def setup(bot):
    """åŠ è½½æ’ä»¶æ—¶è°ƒç”¨çš„åˆå§‹åŒ–å‡½æ•°"""
    await bot.add_cog(RSS(bot)) 