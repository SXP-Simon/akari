import discord
from discord.ext import commands, tasks
import aiohttp
import time
import re
import json
import os
import ssl
import asyncio
from dataclasses import dataclass
from typing import List, Dict, Optional, Union
from bs4 import BeautifulSoup
from lxml import etree
from urllib.parse import urlparse
import logging
from datetime import datetime
import asyncio
import traceback
from ..bot.utils import EmbedBuilder
import html

# =====================
# akari.plugins.rss_plugin
# =====================

"""
RssPlugin: RSS è®¢é˜…ä¸æ¨é€æ’ä»¶

- æ”¯æŒ RSS æºè®¢é˜…ã€ç®¡ç†ä¸æ¨é€
- Discord å‘½ä»¤é›†æˆ
- æ•°æ®æŒä¹…åŒ–ä¸å®šæ—¶ä»»åŠ¡

Attributes:
    bot (commands.Bot): å…³è”çš„ Bot å®ä¾‹
    ...
"""


@dataclass
class RSSConfig:
    """RSSé…ç½®"""
    title_max_length: int = 30
    description_max_length: int = 500
    max_items_per_poll: int = 3
    check_interval: int = 5
    is_hide_url: bool = False
    pic_config: Dict[str, Union[bool, int]] = None
    verify_ssl: bool = True  # æ–°å¢ï¼šæ˜¯å¦éªŒè¯SSLè¯ä¹¦

    def __post_init__(self):
        if self.pic_config is None:
            self.pic_config = {
                "is_read_pic": True,
                "is_adjust_pic": False,
                "max_pic_item": 3
            }


@dataclass
class RSSItem:
    chan_title: str
    title: str
    link: str
    description: str
    pubDate: str
    pubDate_timestamp: int
    pic_urls: List[str]
    source_type: str = "RSS"  # RSS æˆ– Atom
    author: str = ""
    categories: List[str] = None
    icon_url: str = ""
    content: str = ""  # å®Œæ•´å†…å®¹
    summary: str = ""  # æ‘˜è¦

    def __post_init__(self):
        if self.categories is None:
            self.categories = []

    def __str__(self):
        return f"{self.title} - {self.link} - {self.description} - {self.pubDate}"


class RSSError(Exception):
    """RSSé”™è¯¯åŸºç±»"""
    pass


class RSSNetworkError(RSSError):
    """RSSç½‘ç»œé”™è¯¯"""
    pass


class RSSParseError(RSSError):
    """RSSè§£æé”™è¯¯"""
    pass


class RSSFeed:
    def __init__(self, url: str, channel_id: int, cron_expr: str = "*/5 * * * *"):
        self.url = url
        self.channel_id = channel_id
        self.cron_expr = cron_expr
        self.last_update = int(time.time())
        self.latest_link = ""
        self.error_count = 0
        self.last_error = None
        self.last_success = int(time.time())


class RSSManager:
    def __init__(self, config_path: str = "data/rss/rss_data.json"):
        self.config_path = config_path
        self.feeds = {}
        self.load_data()

    def load_data(self):
        """ä»æ•°æ®æ–‡ä»¶ä¸­åŠ è½½æ•°æ®"""
        if not os.path.exists(self.config_path):
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            self.save_data()
            return

        try:
            with open(self.config_path, "r", encoding="utf-8") as f:
                data = json.load(f)
                for url, info in data.items():
                    if url == "settings":
                        continue
                    self.feeds[url] = {}
                    for channel_id, feed_data in info.get("subscribers", {}).items():
                        channel_id = int(channel_id)
                        self.feeds[url][channel_id] = RSSFeed(
                            url=url,
                            channel_id=channel_id,
                            cron_expr=feed_data.get("cron_expr", "*/5 * * * *")
                        )
                        self.feeds[url][channel_id].last_update = feed_data.get(
                            "last_update", int(time.time()))
                        self.feeds[url][channel_id].latest_link = feed_data.get(
                            "latest_link", "")
                        self.feeds[url][channel_id].error_count = feed_data.get(
                            "error_count", 0)
                        self.feeds[url][channel_id].last_error = feed_data.get(
                            "last_error")
                        self.feeds[url][channel_id].last_success = feed_data.get(
                            "last_success", int(time.time()))
        except Exception as e:
            logging.error(f"åŠ è½½RSSæ•°æ®å¤±è´¥: {str(e)}")
            self.feeds = {}

    def save_data(self):
        """ä¿å­˜æ•°æ®åˆ°æ•°æ®æ–‡ä»¶"""
        try:
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            data = {}
            for url, channels in self.feeds.items():
                data[url] = {
                    "subscribers": {},
                    "info": {}  # ç”¨äºå­˜å‚¨é¢‘é“ä¿¡æ¯
                }
                for channel_id, feed in channels.items():
                    data[url]["subscribers"][str(channel_id)] = {
                        "cron_expr": feed.cron_expr,
                        "last_update": feed.last_update,
                        "latest_link": feed.latest_link,
                        "error_count": feed.error_count,
                        "last_error": feed.last_error,
                        "last_success": feed.last_success
                    }

            with open(self.config_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            logging.error(f"ä¿å­˜RSSæ•°æ®å¤±è´¥: {str(e)}")

    def add_feed(self, url: str, channel_id: int, cron_expr: str) -> bool:
        """æ·»åŠ æ–°çš„è®¢é˜…"""
        if url not in self.feeds:
            self.feeds[url] = {}

        if channel_id in self.feeds[url]:
            return False

        self.feeds[url][channel_id] = RSSFeed(url, channel_id, cron_expr)
        self.save_data()
        return True

    def remove_feed(self, url: str, channel_id: int) -> bool:
        """ç§»é™¤è®¢é˜…"""
        if url not in self.feeds or channel_id not in self.feeds[url]:
            return False

        del self.feeds[url][channel_id]
        if not self.feeds[url]:
            del self.feeds[url]
        self.save_data()
        return True

    def get_channel_feeds(self, channel_id: int) -> List[RSSFeed]:
        """è·å–é¢‘é“çš„æ‰€æœ‰è®¢é˜…"""
        result = []
        for url, channels in self.feeds.items():
            if channel_id in channels:
                result.append(channels[channel_id])
        return result


class RSS(commands.Cog):
    """RSSè®¢é˜…æ’ä»¶"""

    def __init__(self, bot):
        self.bot = bot
        self.logger = logging.getLogger(f"discord.{self.__class__.__name__}")
        self.config_path = "data/rss/rss_config.json"
        self.rss_manager = RSSManager()

        # åŠ è½½æˆ–åˆ›å»ºé»˜è®¤é…ç½®
        self.config = self._load_or_create_config()

        # è®¾ç½®SSLä¸Šä¸‹æ–‡
        self.ssl_context = self._create_ssl_context()

        # åˆ›å»ºRSSæ£€æŸ¥ä»»åŠ¡
        self._setup_rss_task()

    def _load_or_create_config(self):
        """åŠ è½½æˆ–åˆ›å»ºé»˜è®¤é…ç½®"""
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return RSSConfig(
                        title_max_length=data.get("title_max_length", 30),
                        description_max_length=data.get(
                            "description_max_length", 500),
                        max_items_per_poll=data.get("max_items_per_poll", 3),
                        check_interval=data.get("check_interval", 5),
                        is_hide_url=data.get("is_hide_url", False),
                        pic_config=data.get("pic_config", None),
                        verify_ssl=data.get("verify_ssl", True)  # æ–°å¢ï¼šSSLéªŒè¯é…ç½®
                    )
            else:
                config = RSSConfig()
                self._save_config(config)
                return config
        except Exception as e:
            self.logger.error(f"åŠ è½½RSSé…ç½®å¤±è´¥: {str(e)}")
            return RSSConfig()

    def _save_config(self, config: RSSConfig):
        """ä¿å­˜é…ç½®"""
        try:
            os.makedirs(os.path.dirname(self.config_path), exist_ok=True)
            data = {
                "title_max_length": config.title_max_length,
                "description_max_length": config.description_max_length,
                "max_items_per_poll": config.max_items_per_poll,
                "check_interval": config.check_interval,
                "is_hide_url": config.is_hide_url,
                "pic_config": config.pic_config,
                "verify_ssl": config.verify_ssl  # æ–°å¢ï¼šSSLéªŒè¯é…ç½®
            }
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            self.logger.error(f"ä¿å­˜RSSé…ç½®å¤±è´¥: {str(e)}")

    def _create_ssl_context(self) -> ssl.SSLContext:
        """åˆ›å»ºSSLä¸Šä¸‹æ–‡"""
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = True
        ssl_context.verify_mode = ssl.CERT_REQUIRED
        return ssl_context

    def _setup_rss_task(self):
        """è®¾ç½®RSSæ£€æŸ¥ä»»åŠ¡"""
        interval = self.config.check_interval

        @tasks.loop(minutes=interval)
        async def check_rss_updates():
            """å®šæœŸæ£€æŸ¥RSSæ›´æ–°"""
            for url, channels in self.rss_manager.feeds.items():
                for channel_id, feed in channels.items():
                    try:
                        channel = self.bot.get_channel(channel_id)
                        if not channel:
                            self.logger.warning(
                                f"æ‰¾ä¸åˆ°é¢‘é“ {channel_id}ï¼Œè·³è¿‡RSSæ£€æŸ¥: {url}")
                            continue

                        items = await self.fetch_rss_items(
                            url,
                            after_timestamp=feed.last_update,
                            after_link=feed.latest_link
                        )

                        if not items:
                            continue

                        for item in items:
                            embed = await self._create_rss_embed(item)
                            try:
                                await channel.send(embed=embed)
                            except discord.HTTPException as e:
                                self.logger.error(
                                    f"å‘é€RSSæ¶ˆæ¯å¤±è´¥ {url} -> {channel_id}: {str(e)}")
                                continue

                        feed.last_update = max(feed.last_update, max(
                            (item.pubDate_timestamp for item in items), default=feed.last_update))
                        if items:
                            feed.latest_link = items[0].link

                        # æ›´æ–°æˆåŠŸçŠ¶æ€
                        feed.error_count = 0
                        feed.last_error = None
                        feed.last_success = int(time.time())
                        self.rss_manager.save_data()

                    except Exception as e:
                        feed.error_count += 1
                        feed.last_error = f"{str(e)}\n{traceback.format_exc()}"
                        self.logger.error(
                            f"æ£€æŸ¥RSSæ›´æ–°å¤±è´¥ {url} -> {channel_id}: {str(e)}\n{traceback.format_exc()}")
                        self.rss_manager.save_data()

                        # å¦‚æœè¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œå‘é€è­¦å‘Š
                        if feed.error_count >= 3:
                            try:
                                embed = EmbedBuilder.error(
                                    title="RSSè®¢é˜…å¼‚å¸¸",
                                    description=f"è®¢é˜…æº `{url}` å·²è¿ç»­ {feed.error_count} æ¬¡æ›´æ–°å¤±è´¥\n"
                                    f"æœ€åä¸€æ¬¡é”™è¯¯: {str(e)}\n"
                                    f"å¦‚æœé—®é¢˜æŒç»­å­˜åœ¨ï¼Œå»ºè®®ä½¿ç”¨ `!rss remove {url}` å–æ¶ˆè®¢é˜…"
                                )
                                await channel.send(embed=embed)
                            except:
                                pass

        @check_rss_updates.before_loop
        async def before_check():
            await self.bot.wait_until_ready()

        self.check_rss_updates = check_rss_updates
        self.check_rss_updates.start()

    async def _create_rss_embed(self, item: RSSItem) -> discord.Embed:
        """åˆ›å»ºRSSæ¶ˆæ¯çš„Embed"""
        # å¤„ç†æè¿°
        description = self.clean_html(item.description)
        logging.info(f"description: {description}")
        if len(description) > self.config.description_max_length:
            description = description[:self.config.description_max_length] + "..."

        # æ ¹æ®æºç±»å‹è®¾ç½®ä¸åŒçš„é¢œè‰²å’Œå›¾æ ‡
        if "github.com" in item.link:
            color = 0x24292e  # GitHubæ·±è‰²
            icon_url = "https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png"
            title = f"ğŸ”” {item.title}"
        else:
            color = 0xFFA500  # RSSæ©™è‰²
            icon_url = None
            title = item.title

        # åˆ›å»ºåµŒå…¥æ¶ˆæ¯
        embed = discord.Embed(
            title=title,
            url=item.link if not self.config.is_hide_url else None,
            description=description,
            color=color,
            timestamp=datetime.fromtimestamp(
                item.pubDate_timestamp) if item.pubDate_timestamp else discord.utils.utcnow()
        )

        # æ·»åŠ æ¥æºä¿¡æ¯
        if icon_url:
            embed.set_author(name=item.chan_title, icon_url=icon_url)
        else:
            embed.set_author(name=item.chan_title)

        # æ·»åŠ å›¾ç‰‡
        if item.pic_urls and self.config.pic_config["is_read_pic"]:
            max_pics = self.config.pic_config["max_pic_item"]
            for i, pic_url in enumerate(item.pic_urls[:max_pics]):
                if i == 0:
                    embed.set_image(url=pic_url)
                else:
                    embed.add_field(
                        name=f"é™„å›¾ {i+1}",
                        value=f"[æŸ¥çœ‹å›¾ç‰‡]({pic_url})",
                        inline=True
                    )

        return embed

    def _format_error(self, error: Exception) -> str:
        """æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯"""
        if isinstance(error, aiohttp.ClientError):
            return f"ç½‘ç»œé”™è¯¯: {str(error)}\nå»ºè®®æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•"
        elif isinstance(error, etree.XMLSyntaxError):
            return f"XMLè§£æé”™è¯¯: {str(error)}\næºæ ¼å¼å¯èƒ½ä¸æ­£ç¡®"
        elif isinstance(error, RSSNetworkError):
            if "SSL" in str(error):
                return f"{str(error)}\nå¯ä»¥å°è¯•ä½¿ç”¨ `!rss config set verify_ssl false` å…³é—­SSLéªŒè¯"
            return str(error)
        elif isinstance(error, RSSParseError):
            return f"è§£æé”™è¯¯: {str(error)}\næºå†…å®¹å¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„RSS/Atomæ ¼å¼"
        else:
            return f"æœªçŸ¥é”™è¯¯: {str(error)}"

    async def _handle_feed_error(self, ctx, url: str, error: Exception):
        """å¤„ç†Feedé”™è¯¯"""
        error_msg = self._format_error(error)

        embed = EmbedBuilder.error(
            title="RSSå¤„ç†å¤±è´¥",
            description=f"å¤„ç†RSSæºæ—¶å‘ç”Ÿé”™è¯¯:\n```{error_msg}```"
        )

        embed.add_field(
            name="æºä¿¡æ¯",
            value=f"**URL:** {url}",
            inline=False
        )

        if isinstance(error, RSSNetworkError) and "SSL" in str(error):
            embed.add_field(
                name="å»ºè®®æ“ä½œ",
                value="1. æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®\n2. å°è¯•å…³é—­SSLéªŒè¯: `!rss config set verify_ssl false`\n3. ç­‰å¾…å‡ åˆ†é’Ÿåé‡è¯•",
                inline=False
            )
        elif isinstance(error, RSSParseError):
            embed.add_field(
                name="å»ºè®®æ“ä½œ",
                value="1. æ£€æŸ¥URLæ˜¯å¦ä¸ºæœ‰æ•ˆçš„RSS/Atomæº\n2. åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€URLæ£€æŸ¥å†…å®¹\n3. ä½¿ç”¨ `!rss test <url>` æµ‹è¯•æº",
                inline=False
            )

        await ctx.send(embed=embed)

    def cog_unload(self):
        """æ’ä»¶å¸è½½æ—¶çš„æ¸…ç†å·¥ä½œ"""
        if self.check_rss_updates.is_running():
            self.check_rss_updates.cancel()

    def _normalize_url(self, url: str) -> str:
        """è§„èŒƒåŒ–URL"""
        # å¤„ç†GitHub URL
        if "github.com" in url:
            # ç§»é™¤æœ«å°¾çš„æ–œæ 
            url = url.rstrip("/")

            # å¤„ç†ç”¨æˆ·æ´»åŠ¨feed
            if url.endswith(".atom"):
                return url

            # å¤„ç†ä»“åº“feed
            if not url.endswith("/releases.atom"):
                # æ£€æŸ¥æ˜¯å¦æ˜¯ä»“åº“URL
                parts = url.split("/")
                if len(parts) >= 5 and parts[2] == "github.com":
                    # æ·»åŠ releases.atom
                    return f"{url}/releases.atom"

        return url

    def _handle_ssl_error(self, error: Exception) -> str:
        """å¤„ç†SSLé”™è¯¯"""
        error_str = str(error)
        if "CERTIFICATE_VERIFY_FAILED" in error_str:
            return "SSLè¯ä¹¦éªŒè¯å¤±è´¥ï¼Œå¯èƒ½æ˜¯è‡ªç­¾åè¯ä¹¦æˆ–è¯ä¹¦è¿‡æœŸ"
        elif "WRONG_VERSION_NUMBER" in error_str:
            return "SSLç‰ˆæœ¬ä¸åŒ¹é…ï¼ŒæœåŠ¡å™¨å¯èƒ½ä¸æ”¯æŒå®‰å…¨è¿æ¥"
        elif "DECRYPTION_FAILED_OR_BAD_RECORD_MAC" in error_str:
            return "SSLè§£å¯†å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–ä»£ç†è®¾ç½®å¯¼è‡´"
        else:
            return f"SSLé”™è¯¯: {error_str}"

    async def parse_rss_feed(self, url: str) -> Optional[tuple[str, str]]:
        """è§£æRSSé¢‘é“ä¿¡æ¯"""
        try:
            # è§„èŒƒåŒ–URL
            url = self._normalize_url(url)

            connector = aiohttp.TCPConnector(ssl=self.ssl_context)
            timeout = aiohttp.ClientTimeout(total=30)
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                "Accept": "application/atom+xml,application/xml,application/rss+xml,text/xml;q=0.9,*/*;q=0.8"
            }

            async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
                async with session.get(url, headers=headers) as resp:
                    if resp.status != 200:
                        self.logger.error(
                            f"è·å–RSSæºå¤±è´¥: {url}, çŠ¶æ€ç : {resp.status}")
                        return None

                    try:
                        text = await resp.text()
                    except UnicodeDecodeError:
                        # å¦‚æœUTF-8è§£ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç 
                        content = await resp.read()
                        for encoding in ['utf-8', 'gbk', 'gb2312', 'iso-8859-1']:
                            try:
                                text = content.decode(encoding)
                                break
                            except UnicodeDecodeError:
                                continue
                        else:
                            self.logger.error(f"æ— æ³•è§£ç RSSå†…å®¹: {url}")
                            return None

                    try:
                        root = etree.fromstring(text.encode('utf-8'))
                    except etree.XMLSyntaxError as e:
                        # å°è¯•ä¿®å¤å¸¸è§çš„XMLé—®é¢˜
                        text = text.replace('&', '&amp;')
                        try:
                            root = etree.fromstring(text.encode('utf-8'))
                        except etree.XMLSyntaxError:
                            self.logger.error(
                                f"è§£æRSS XMLå¤±è´¥: {url}, é”™è¯¯: {str(e)}")
                            return None

                    # è·å–æ‰€æœ‰å‘½åç©ºé—´
                    namespaces = {}
                    for key, value in root.nsmap.items():
                        if key is not None:
                            namespaces[key] = value
                        else:
                            # å¤„ç†é»˜è®¤å‘½åç©ºé—´
                            namespaces['default'] = value

                    # æ£€æµ‹feedç±»å‹
                    is_atom = root.tag.endswith('feed')

                    # æ ¹æ®feedç±»å‹é€‰æ‹©ä¸åŒçš„XPath
                    if is_atom:
                        title_paths = [
                            "//default:title/text()",
                            "//atom:title/text()",
                            "//title/text()"
                        ]
                        desc_paths = [
                            "//default:subtitle/text()",
                            "//atom:subtitle/text()",
                            "//default:summary/text()",
                            "//atom:summary/text()"
                        ]
                    else:
                        title_paths = [
                            "//channel/title/text()",
                            "//default:title/text()",
                            "//title/text()"
                        ]
                        desc_paths = [
                            "//channel/description/text()",
                            "//default:description/text()",
                            "//description/text()"
                        ]

                    # å°è¯•è·å–æ ‡é¢˜
                    title = None
                    for xpath in title_paths:
                        try:
                            titles = root.xpath(xpath, namespaces=namespaces)
                            if titles:
                                title = titles[0].strip()
                            break
                        except:
                            continue

                    # å°è¯•è·å–æè¿°
                    description = None
                    for xpath in desc_paths:
                        try:
                            descs = root.xpath(xpath, namespaces=namespaces)
                            if descs:
                                description = descs[0].strip()
                            break
                        except:
                            continue

                    if not title:
                        title = "æœªçŸ¥é¢‘é“"
                    if not description:
                        description = "æ— æè¿°"

                    return title, description

        except aiohttp.ClientError as e:
            self.logger.error(f"è·å–RSSæºç½‘ç»œé”™è¯¯: {url} - {str(e)}")
            raise RSSNetworkError(f"ç½‘ç»œé”™è¯¯: {str(e)}")
        except Exception as e:
            self.logger.error(f"è§£æRSSæºå¤±è´¥: {url} - {str(e)}")
            raise RSSParseError(f"è§£æé”™è¯¯: {str(e)}")

    async def fetch_rss_items(
        self,
        url: str,
        after_timestamp: int = 0,
        after_link: str = "",
        num: int = None
    ) -> List[RSSItem]:
        """ä»ç«™ç‚¹æ‹‰å–RSSä¿¡æ¯"""
        try:
            # è§„èŒƒåŒ–URL
            url = self._normalize_url(url)

            # é…ç½®SSLä¸Šä¸‹æ–‡
            ssl_context = ssl.create_default_context()
            ssl_context.check_hostname = False
            ssl_context.verify_mode = ssl.CERT_NONE

            # é…ç½®è¿æ¥å™¨å’Œè¶…æ—¶
            connector = aiohttp.TCPConnector(ssl=ssl_context)
            timeout = aiohttp.ClientTimeout(total=30)

            # è®¾ç½®è¯·æ±‚å¤´
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
                "Accept": "application/atom+xml,application/xml,application/rss+xml,text/xml;q=0.9,*/*;q=0.8",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Connection": "close"  # é¿å…ä¿æŒè¿æ¥
            }

            async with aiohttp.ClientSession(
                connector=connector,
                timeout=timeout,
                headers=headers,
                trust_env=True
            ) as session:
                async with session.get(url) as resp:
                    if resp.status != 200:
                        self.logger.error(
                            f"è·å–RSSæºå¤±è´¥: {url}, çŠ¶æ€ç : {resp.status}")
                        return []

                    try:
                        text = await resp.text()
                        # å°è¯•ä¿®å¤å¸¸è§çš„XMLé—®é¢˜
                        text = text.replace('xmlns=""', '')  # ç§»é™¤ç©ºçš„å‘½åç©ºé—´å£°æ˜
                        # ç§»é™¤ç©ºçš„å‰ç¼€å‘½åç©ºé—´
                        text = re.sub(r'xmlns:([a-zA-Z0-9]+)=""', '', text)

                        # è§£æXML
                        parser = etree.XMLParser(recover=True)  # å¯ç”¨æ¢å¤æ¨¡å¼
                        root = etree.fromstring(
                            text.encode('utf-8'), parser=parser)
                    except Exception as e:
                        self.logger.error(f"è§£æRSSå†…å®¹å¤±è´¥: {url} - {str(e)}")
                        return []

                    # è·å–æ‰€æœ‰å‘½åç©ºé—´
                    namespaces = {}
                    for key, value in root.nsmap.items():
                        if key is None:
                            namespaces['default'] = value
                            namespaces['atom'] = value  # ä¸ºAtomæ ¼å¼æ·»åŠ æ˜¾å¼å‘½åç©ºé—´
                        else:
                            namespaces[key] = value

                    # æ£€æµ‹feedç±»å‹
                    is_atom = 'http://www.w3.org/2005/Atom' in root.nsmap.values()

                    # æ ¹æ®feedç±»å‹é€‰æ‹©ä¸åŒçš„XPath
                    if is_atom:
                        items = root.xpath(
                            "//entry | //atom:entry", namespaces=namespaces)
                        chan_title = self._get_feed_title(
                            root, namespaces, is_atom)
                        if "github.com" in url:
                            # ä¸ºGitHubæºæ·»åŠ é¢å¤–ä¿¡æ¯
                            repo_info = self._get_github_repo_info(
                                root, namespaces)
                            if repo_info:
                                chan_title = f"GitHub - {repo_info}"
                    else:
                        items = root.xpath("//item", namespaces=namespaces)
                        chan_title = self._get_feed_title(
                            root, namespaces, is_atom)

                    if not items:
                        self.logger.error(f"æœªæ‰¾åˆ°RSS/Atomæ¡ç›®: {url}")
                        return []

                    max_items = num if num is not None else self.config.max_items_per_poll
                    rss_items = []

                    for item in items:
                        try:
                            # æ ¹æ®feedç±»å‹è·å–ä¿¡æ¯
                            if is_atom:
                                title = self._get_text(
                                    item, ["title", "atom:title"], namespaces)
                                link = self._get_link(item, namespaces)
                                content = self._get_text(item, [
                                    "content", "atom:content",
                                    "summary", "atom:summary"
                                ], namespaces)
                                updated = self._get_text(item, [
                                    "updated", "atom:updated",
                                    "published", "atom:published"
                                ], namespaces)
                            else:
                                title = self._get_text(
                                    item, ["title"], namespaces)
                                link = self._get_text(
                                    item, ["link"], namespaces)
                                content = self._get_text(
                                    item, ["description"], namespaces)
                                updated = self._get_text(
                                    item, ["pubDate"], namespaces)

                            if not title or not link:
                                continue

                            if not content:
                                content = "æ— æè¿°"

                            # å¤„ç†æ—¥æœŸ
                            pub_date_timestamp = self._parse_date(updated)

                            # æå–å›¾ç‰‡
                            pic_urls = self.extract_images(content)

                            # æ¸…ç†æè¿°æ–‡æœ¬
                            description = self.strip_html(content)

                            if pub_date_timestamp > after_timestamp or (pub_date_timestamp == 0 and link != after_link):
                                rss_items.append(
                                    RSSItem(
                                        chan_title=chan_title,
                                        title=title,
                                        link=link,
                                        description=description,
                                        pubDate=updated or "",
                                        pubDate_timestamp=pub_date_timestamp,
                                        pic_urls=pic_urls
                                    )
                                )

                                if max_items > 0 and len(rss_items) >= max_items:
                                    break

                        except Exception as e:
                            self.logger.error(f"è§£æRSSæ¡ç›®å¤±è´¥: {url} - {str(e)}")
                            continue

                    return rss_items

        except Exception as e:
            self.logger.error(
                f"è·å–RSSå†…å®¹å¤±è´¥: {url} - {str(e)}\n{traceback.format_exc()}")
            return []

    def _get_feed_title(self, root, namespaces: dict, is_atom: bool) -> str:
        """è·å–Feedæ ‡é¢˜"""
        if is_atom:
            for xpath in ["//title", "//atom:title"]:
                title = self._get_text(root, [xpath], namespaces)
                if title:
                    return title
        else:
            for xpath in ["//channel/title", "//title"]:
                title = self._get_text(root, [xpath], namespaces)
                if title:
                    return title
        return "æœªçŸ¥é¢‘é“"

    def _get_github_repo_info(self, root, namespaces: dict) -> Optional[str]:
        """è·å–GitHubä»“åº“ä¿¡æ¯"""
        try:
            # è·å–ä»“åº“åç§°
            repo_name = self._get_text(root, ["//title"], namespaces)
            if repo_name:
                repo_name = repo_name.replace(" - Atom", "").strip()

            # è·å–ä»“åº“æè¿°
            description = self._get_text(
                root, ["//subtitle", "//atom:subtitle"], namespaces)

            if repo_name:
                if description:
                    return f"{repo_name} - {description}"
                return repo_name
            return None
        except:
            return None

    def _get_text(self, element, paths: List[str], namespaces: dict) -> Optional[str]:
        """è·å–XMLå…ƒç´ çš„æ–‡æœ¬å†…å®¹"""
        for path in paths:
            try:
                elements = element.xpath(path, namespaces=namespaces)
                if elements and elements[0].text:
                    return elements[0].text.strip()
            except:
                continue
        return None

    def _get_link(self, element, namespaces: dict) -> Optional[str]:
        """è·å–Atom feedä¸­çš„é“¾æ¥"""
        # é¦–å…ˆå°è¯•è·å–linkå…ƒç´ çš„hrefå±æ€§
        for path in ["default:link/@href", "atom:link/@href", "link/@href"]:
            try:
                hrefs = element.xpath(path, namespaces=namespaces)
                if hrefs:
                    return hrefs[0].strip()
            except:
                continue

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°hrefå±æ€§ï¼Œå°è¯•è·å–linkå…ƒç´ çš„æ–‡æœ¬å†…å®¹
        for path in ["default:link/text()", "atom:link/text()", "link/text()"]:
            try:
                links = element.xpath(path, namespaces=namespaces)
                if links:
                    return links[0].strip()
            except:
                continue

        return None

    def _parse_date(self, date_str: Optional[str]) -> int:
        """è§£ææ—¥æœŸå­—ç¬¦ä¸²ä¸ºæ—¶é—´æˆ³"""
        if not date_str:
            return 0

        date_formats = [
            "%a, %d %b %Y %H:%M:%S %z",  # RSSæ ‡å‡†æ ¼å¼
            "%Y-%m-%dT%H:%M:%S%z",       # ISO 8601
            "%Y-%m-%dT%H:%M:%SZ",        # ISO 8601 UTC
            "%Y-%m-%d %H:%M:%S",         # ç®€å•æ ¼å¼
            "%a, %d %b %Y %H:%M:%S GMT",  # å¦ä¸€ç§RSSæ ¼å¼
            "%Y-%m-%dT%H:%M:%S.%f%z",    # å¸¦æ¯«ç§’çš„ISO 8601
            "%Y-%m-%dT%H:%M:%S.%fZ"      # å¸¦æ¯«ç§’çš„ISO 8601 UTC
        ]

        # é¢„å¤„ç†æ—¥æœŸå­—ç¬¦ä¸²
        date_str = date_str.strip()
        if "GMT" in date_str:
            date_str = date_str.replace("GMT", "+0000")
        if date_str.endswith("Z"):
            date_str = date_str[:-1] + "+0000"

        # å°è¯•ä¸åŒçš„æ—¥æœŸæ ¼å¼
        for date_format in date_formats:
            try:
                parsed_time = time.strptime(date_str, date_format)
                return int(time.mktime(parsed_time))
            except ValueError:
                continue

        return int(time.time())

    def strip_html(self, html: str) -> str:
        """ç§»é™¤HTMLæ ‡ç­¾"""
        soup = BeautifulSoup(html, "html.parser")
        text = soup.get_text()
        return re.sub(r"\n+", "\n", text)

    def extract_images(self, html: str) -> List[str]:
        """æå–HTMLä¸­çš„å›¾ç‰‡URL"""
        soup = BeautifulSoup(html, "html.parser")
        return [img.get('src') for img in soup.find_all('img') if img.get('src')]

    def get_root_url(self, url: str) -> str:
        """è·å–URLçš„æ ¹åŸŸå"""
        parsed_url = urlparse(url)
        return f"{parsed_url.scheme}://{parsed_url.netloc}"

    def clean_html(self,html_content):
        """æ¸…ç† HTML æ ‡ç­¾å¹¶è½¬æ¢å®ä½“å­—ç¬¦"""
        if not html_content:
            return ""
        # è½¬æ¢ HTML å®ä½“å­—ç¬¦
        unescaped = html.unescape(html_content)
        # ç§»é™¤ HTML æ ‡ç­¾
        soup = BeautifulSoup(unescaped, "html.parser")
        # è·å–çº¯æ–‡æœ¬å†…å®¹
        text = soup.get_text()
        # å¤„ç†å¤šä½™çš„ç©ºç™½å­—ç¬¦
        cleaned_text = " ".join(text.split())
        return cleaned_text

    @commands.group(name="rss", invoke_without_command=True)
    async def rss(self, ctx):
        """RSSè®¢é˜…ç®¡ç†"""
        if ctx.invoked_subcommand is None:
            commands = {
                "!rss add <url> [cron]": "æ·»åŠ RSSè®¢é˜…ï¼Œå¯é€‰æŒ‡å®šæ£€æŸ¥é—´éš”",
                "!rss remove <url>": "ç§»é™¤RSSè®¢é˜…",
                "!rss list": "æŸ¥çœ‹å½“å‰é¢‘é“çš„RSSè®¢é˜…åˆ—è¡¨",
                "!rss info <url>": "æŸ¥çœ‹RSSè®¢é˜…è¯¦ç»†ä¿¡æ¯",
                "!rss test <url>": "æµ‹è¯•RSSè®¢é˜…æº",
                "!rss config": "æŸ¥çœ‹å’Œä¿®æ”¹RSSé…ç½®"
            }
            await ctx.send(embed=EmbedBuilder.menu(
                title="RSSè®¢é˜…ç®¡ç†",
                description="ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç®¡ç†RSSè®¢é˜…ï¼š",
                commands=commands
            ))

    @rss.command(name="add")
    async def add_feed(self, ctx, url: str, cron: str = "*/5 * * * *"):
        """æ·»åŠ RSSè®¢é˜…"""
        try:
            # è§„èŒƒåŒ–URL
            url = self._normalize_url(url)

            # æµ‹è¯•RSSæºæ˜¯å¦å¯ç”¨
            feed_info = await self.parse_rss_feed(url)
            if not feed_info:
                await ctx.send(embed=EmbedBuilder.error(
                    title="æ·»åŠ å¤±è´¥",
                    description="æ— æ³•è·å–RSSæºä¿¡æ¯ï¼Œè¯·æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®"
                ))
                return

            title, description = feed_info
            if self.rss_manager.add_feed(url, ctx.channel.id, cron):
                # åˆ›å»ºæˆåŠŸæç¤º
                embed = EmbedBuilder.success(
                    title="RSSè®¢é˜…æ·»åŠ æˆåŠŸ",
                    description=f"**{title}**\n{description}"
                )

                # æ·»åŠ è®¢é˜…è®¾ç½®
                cron_desc = self._format_cron(cron)
                embed.add_field(
                    name="è®¢é˜…è®¾ç½®",
                    value=f"**æ£€æŸ¥é—´éš”:** {cron_desc}\n**URL:** {url}",
                    inline=False
                )

                # å°è¯•è·å–æœ€æ–°æ–‡ç« 
                try:
                    items = await self.fetch_rss_items(url, num=1)
                    if items:
                        item = items[0]
                        embed.add_field(
                            name="æœ€æ–°æ–‡ç« ",
                            value=f"**[{item.title}]({item.link})**\n{item.description[:100]}...",
                            inline=False
                        )
                except Exception as e:
                    self.logger.error(f"è·å–æœ€æ–°æ–‡ç« å¤±è´¥: {url} - {str(e)}")

                await ctx.send(embed=embed)
            else:
                await ctx.send(embed=EmbedBuilder.warning(
                    title="æ·»åŠ å¤±è´¥",
                    description="è¯¥RSSæºå·²ç»è®¢é˜…"
                ))
        except RSSNetworkError as e:
            await ctx.send(embed=EmbedBuilder.error(
                title="æ·»åŠ å¤±è´¥",
                description=f"ç½‘ç»œé”™è¯¯: {str(e)}\nå¦‚æœæ˜¯SSLé”™è¯¯ï¼Œè¯·å°è¯•ä½¿ç”¨ `!rss config set verify_ssl false` å…³é—­SSLéªŒè¯"
            ))
        except RSSParseError as e:
            await ctx.send(embed=EmbedBuilder.error(
                title="æ·»åŠ å¤±è´¥",
                description=f"è§£æé”™è¯¯: {str(e)}"
            ))
        except Exception as e:
            await ctx.send(embed=EmbedBuilder.error(
                title="æ·»åŠ å¤±è´¥",
                description=f"å‘ç”Ÿé”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            ))

    def _format_cron(self, cron: str) -> str:
        """æ ¼å¼åŒ–cronè¡¨è¾¾å¼ä¸ºå‹å¥½æ˜¾ç¤º"""
        parts = cron.split()
        if len(parts) == 5 and parts[0].startswith("*/"):
            try:
                minutes = int(parts[0][2:])
                if minutes == 1:
                    return "æ¯åˆ†é’Ÿ"
                return f"æ¯{minutes}åˆ†é’Ÿ"
            except:
                pass
        return cron

    @rss.command(name="remove")
    async def remove_feed(self, ctx, url: str):
        """ç§»é™¤RSSè®¢é˜…
        ç”¨æ³•ï¼š!rss remove <url>
        ä¾‹å¦‚ï¼š!rss remove https://rsshub.app/cngal/weekly
        """
        if self.rss_manager.remove_feed(url, ctx.channel.id):
            await ctx.send(embed=EmbedBuilder.success(
                title="RSSè®¢é˜…å·²ç§»é™¤"
            ))
        else:
            await ctx.send(embed=EmbedBuilder.error(
                title="ç§»é™¤å¤±è´¥",
                description="æœªæ‰¾åˆ°è¯¥RSSè®¢é˜…"
            ))

    @rss.command(name="list")
    async def list_feeds(self, ctx):
        """åˆ—å‡ºå½“å‰é¢‘é“çš„RSSè®¢é˜…
        ç”¨æ³•ï¼š!rss list
        """
        feeds = self.rss_manager.get_channel_feeds(ctx.channel.id)
        if not feeds:
            await ctx.send(embed=EmbedBuilder.info(
                title="RSSè®¢é˜…åˆ—è¡¨",
                description="ğŸ“­ å½“å‰é¢‘é“æ²¡æœ‰RSSè®¢é˜…"
            ))
            return

        fields = []
        for feed in feeds:
            feed_info = await self.parse_rss_feed(feed.url)
            title = feed_info[0] if feed_info else "æœªçŸ¥é¢‘é“"

            status = "âœ… æ­£å¸¸"
            if feed.error_count > 0:
                status = f"âš ï¸ å¼‚å¸¸ ({feed.error_count}æ¬¡å¤±è´¥)"

            field_value = (
                f"**URL:** {feed.url}\n"
                f"**æ›´æ–°é—´éš”:** {feed.cron_expr}\n"
                f"**çŠ¶æ€:** {status}\n"
                f"**æœ€åæ›´æ–°:** <t:{feed.last_update}:R>"
            )

            if feed.last_error:
                field_value += f"\n**æœ€åé”™è¯¯:** ```{feed.last_error[:200]}...```" if len(
                    feed.last_error) > 200 else f"\n**æœ€åé”™è¯¯:** ```{feed.last_error}```"

            fields.append((title, field_value, False))

        embed = EmbedBuilder.stats(
            title="RSSè®¢é˜…åˆ—è¡¨",
            description=f"å½“å‰é¢‘é“å…±æœ‰ {len(feeds)} ä¸ªè®¢é˜…ï¼š",
            author=ctx.author
        )

        # é€ä¸ªæ·»åŠ å­—æ®µ
        for name, value, inline in fields:
            embed.add_field(name=name, value=value, inline=inline)

        await ctx.send(embed=embed)

    @rss.command(name="info")
    async def feed_info(self, ctx, url: str):
        """æŸ¥çœ‹RSSè®¢é˜…è¯¦ç»†ä¿¡æ¯
        ç”¨æ³•ï¼š!rss info <url>
        ä¾‹å¦‚ï¼š!rss info https://rsshub.app/cngal/weekly
        """
        feed = None
        for channel_feeds in self.rss_manager.feeds.get(url, {}).values():
            feed = channel_feeds
            break

        if not feed:
            await ctx.send(embed=EmbedBuilder.error(
                title="è·å–å¤±è´¥",
                description="æœªæ‰¾åˆ°è¯¥RSSè®¢é˜…"
            ))
            return

        try:
            feed_info = await self.parse_rss_feed(url)
            if not feed_info:
                await ctx.send(embed=EmbedBuilder.error(
                    title="è·å–å¤±è´¥",
                    description="æ— æ³•è·å–RSSæºä¿¡æ¯"
                ))
                return

            title, description = feed_info
            embed = EmbedBuilder.info(
                title=title,
                description=description
            )

            # æ·»åŠ åŸºæœ¬ä¿¡æ¯
            embed.add_field(
                name="åŸºæœ¬ä¿¡æ¯",
                value=(
                    f"**URL:** {url}\n"
                    f"**æ›´æ–°é—´éš”:** {feed.cron_expr}\n"
                    f"**æœ€åæ›´æ–°:** <t:{feed.last_update}:R>\n"
                    f"**çŠ¶æ€:** {'âœ… æ­£å¸¸' if feed.error_count == 0 else f'âš ï¸ å¼‚å¸¸ ({feed.error_count}æ¬¡å¤±è´¥)'}"
                ),
                inline=False
            )

            # å°è¯•è·å–æœ€æ–°æ–‡ç« 
            try:
                items = await self.fetch_rss_items(url, num=3)
                if items:
                    latest_items = "\n\n".join(
                        f"**[{item.title}]({item.link})**\n{item.description[:100]}..."
                        for item in items
                    )
                    embed.add_field(
                        name="æœ€æ–°æ–‡ç« ",
                        value=latest_items,
                        inline=False
                    )
            except Exception as e:
                embed.add_field(
                    name="è­¦å‘Š",
                    value=f"è·å–æœ€æ–°æ–‡ç« å¤±è´¥: {str(e)}",
                    inline=False
                )

            # æ·»åŠ é”™è¯¯ä¿¡æ¯
            if feed.last_error:
                embed.add_field(
                    name="æœ€åé”™è¯¯ä¿¡æ¯",
                    value=f"```{feed.last_error[:500]}...```" if len(
                        feed.last_error) > 500 else f"```{feed.last_error}```",
                    inline=False
                )

            await ctx.send(embed=embed)

        except Exception as e:
            await ctx.send(embed=EmbedBuilder.error(
                title="è·å–å¤±è´¥",
                description=f"è·å–RSSä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}\n{traceback.format_exc()}"
            ))

    @rss.command(name="test")
    async def test_feed(self, ctx, url: str):
        """æµ‹è¯•RSSè®¢é˜…æº"""
        try:
            # è§„èŒƒåŒ–URL
            url = self._normalize_url(url)

            # æµ‹è¯•RSSæº
            feed_info = await self.parse_rss_feed(url)
            if not feed_info:
                await ctx.send(embed=EmbedBuilder.error(
                    title="æµ‹è¯•å¤±è´¥",
                    description="æ— æ³•è·å–RSSæºä¿¡æ¯ï¼Œè¯·æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®"
                ))
                return

            title, description = feed_info
            logging.info(f"title: {title}, description: {description}")
            # åˆ›å»ºæµ‹è¯•ç»“æœåµŒå…¥æ¶ˆæ¯
            embed = EmbedBuilder.success(
                title="RSSæºæµ‹è¯•æˆåŠŸ",
                description=f"**{title}**\n{description}"
            )

            # è·å–æœ€æ–°æ–‡ç« 
            try:
                items = await self.fetch_rss_items(url, num=3)
                if items:
                    latest_items = []
                    for i, item in enumerate(items, 1):
                        latest_items.append(
                            f"**{i}. [{item.title}]({item.link})**\n"
                            f"{self.clean_html(item.description)[:100]}..."
                        )

                    embed.add_field(
                        name="æœ€æ–°æ–‡ç« ",
                        value="\n\n".join(latest_items),
                        inline=False
                    )
            except Exception as e:
                embed.add_field(
                    name="è­¦å‘Š",
                    value=f"è·å–æœ€æ–°æ–‡ç« å¤±è´¥: {self._format_error(e)}",
                    inline=False
                )

            await ctx.send(embed=embed)

        except Exception as e:
            await self._handle_feed_error(ctx, url, e)

    @rss.group(name="config")
    @commands.has_permissions(administrator=True)
    async def rss_config(self, ctx):
        """RSSé…ç½®ç®¡ç†ï¼ˆéœ€è¦ç®¡ç†å‘˜æƒé™ï¼‰"""
        if ctx.invoked_subcommand is None:
            current_config = {
                "æ£€æŸ¥é—´éš”": f"{self.config.check_interval} åˆ†é’Ÿ",
                "æ ‡é¢˜æœ€å¤§é•¿åº¦": f"{self.config.title_max_length} å­—ç¬¦",
                "æè¿°æœ€å¤§é•¿åº¦": f"{self.config.description_max_length} å­—ç¬¦",
                "å•æ¬¡è·å–æœ€å¤§æ¡ç›®æ•°": str(self.config.max_items_per_poll),
                "éšè—é“¾æ¥": str(self.config.is_hide_url),
                "SSLéªŒè¯": str(self.ssl_context.verify_mode == ssl.CERT_REQUIRED),
                "å›¾ç‰‡è®¾ç½®": (
                    f"è¯»å–å›¾ç‰‡: {self.config.pic_config['is_read_pic']}\n"
                    f"é˜²å’Œè°å¤„ç†: {self.config.pic_config['is_adjust_pic']}\n"
                    f"æœ€å¤§å›¾ç‰‡æ•°: {self.config.pic_config['max_pic_item']}"
                )
            }

            fields = [(k, v, True) for k, v in current_config.items()]
            await ctx.send(embed=EmbedBuilder.info(
                title="RSS å½“å‰é…ç½®",
                description="ä½¿ç”¨ `!rss config set <é…ç½®é¡¹> <å€¼>` ä¿®æ”¹é…ç½®",
                fields=fields
            ))

    @rss_config.command(name="set")
    async def set_config(self, ctx, key: str, value: str):
        """è®¾ç½®RSSé…ç½®é¡¹"""
        key = key.lower()
        try:
            if key == "verify_ssl":
                val = value.lower() in ["true", "1", "yes", "y"]
                self.ssl_context.verify_mode = ssl.CERT_REQUIRED if val else ssl.CERT_NONE
                await ctx.send(embed=EmbedBuilder.success(
                    title="æ›´æ–°æˆåŠŸ",
                    description=f"SSLéªŒè¯å·²{'å¼€å¯' if val else 'å…³é—­'}"
                ))
            elif key == "check_interval":
                interval = int(value)
                if interval < 1:
                    raise ValueError("æ£€æŸ¥é—´éš”å¿…é¡»å¤§äº0")

                # æ›´æ–°é…ç½®
                self.config.check_interval = interval
                self._save_config(self.config)

                # é‡æ–°åˆ›å»ºä»»åŠ¡
                if self.check_rss_updates.is_running():
                    self.check_rss_updates.cancel()
                self._setup_rss_task()

                await ctx.send(embed=EmbedBuilder.success(
                    title="æ›´æ–°æˆåŠŸ",
                    description=f"RSSæ£€æŸ¥é—´éš”å·²æ›´æ–°ä¸º {interval} åˆ†é’Ÿ"
                ))
            elif key in ["title_max_length", "description_max_length", "max_items_per_poll"]:
                val = int(value)
                if val < 1:
                    raise ValueError(f"{key} å¿…é¡»å¤§äº0")
                setattr(self.config, key, val)
                self._save_config(self.config)
                await ctx.send(embed=EmbedBuilder.success(
                    title="æ›´æ–°æˆåŠŸ",
                    description=f"{key} å·²æ›´æ–°ä¸º {val}"
                ))
            elif key == "is_hide_url":
                val = value.lower() in ["true", "1", "yes", "y"]
                self.config.is_hide_url = val
                self._save_config(self.config)
                await ctx.send(embed=EmbedBuilder.success(
                    title="æ›´æ–°æˆåŠŸ",
                    description=f"éšè—é“¾æ¥å·²{'å¼€å¯' if val else 'å…³é—­'}"
                ))
            elif key.startswith("pic_"):
                pic_key = key[4:]  # ç§»é™¤ "pic_" å‰ç¼€
                if pic_key not in self.config.pic_config:
                    raise ValueError(f"æ— æ•ˆçš„å›¾ç‰‡é…ç½®é¡¹: {pic_key}")

                if pic_key in ["is_read_pic", "is_adjust_pic"]:
                    val = value.lower() in ["true", "1", "yes", "y"]
                else:  # max_pic_item
                    val = int(value)
                    if val < 1:
                        raise ValueError("æœ€å¤§å›¾ç‰‡æ•°å¿…é¡»å¤§äº0")

                self.config.pic_config[pic_key] = val
                self._save_config(self.config)
                await ctx.send(embed=EmbedBuilder.success(
                    title="æ›´æ–°æˆåŠŸ",
                    description=f"å›¾ç‰‡é…ç½® {pic_key} å·²æ›´æ–°ä¸º {val}"
                ))
            else:
                await ctx.send(embed=EmbedBuilder.error(
                    title="æ— æ•ˆçš„é…ç½®é¡¹",
                    description=(
                        "å¯ç”¨çš„é…ç½®é¡¹ï¼š\n"
                        "- verify_ssl (true/false)\n"
                        "- check_interval (åˆ†é’Ÿ)\n"
                        "- title_max_length\n"
                        "- description_max_length\n"
                        "- max_items_per_poll\n"
                        "- is_hide_url\n"
                        "- pic_is_read_pic\n"
                        "- pic_is_adjust_pic\n"
                        "- pic_max_pic_item"
                    )
                ))
        except ValueError as e:
            await ctx.send(embed=EmbedBuilder.error(
                title="é…ç½®æ›´æ–°å¤±è´¥",
                description=str(e)
            ))
        except Exception as e:
            await ctx.send(embed=EmbedBuilder.error(
                title="é…ç½®æ›´æ–°å¤±è´¥",
                description=f"å‘ç”Ÿé”™è¯¯: {str(e)}"
            ))

    async def _create_info_embed(self, feed_info: tuple[str, str], url: str) -> discord.Embed:
        """åˆ›å»ºRSSä¿¡æ¯çš„Embed

        Args:
            feed_info: (æ ‡é¢˜, æè¿°)çš„å…ƒç»„
            url: RSSæºURL
        """
        title, description = feed_info
        embed = EmbedBuilder.info(
            title="RSSæºä¿¡æ¯",
            description=f"**é¢‘é“:** {title}\n**æè¿°:** {description}"
        )

        # å°è¯•è·å–æœ€æ–°æ–‡ç« 
        try:
            items = await self.fetch_rss_items(url, num=1)
            if items:
                embed.add_field(
                    name="æœ€æ–°æ–‡ç« ",
                    value=f"**{items[0].title}**\n{items[0].description[:100]}...",
                    inline=False
                )
        except Exception as e:
            embed.add_field(
                name="è­¦å‘Š",
                value=f"è·å–æœ€æ–°æ–‡ç« å¤±è´¥: {str(e)}",
                inline=False
            )

        return embed


async def setup(bot):
    """åŠ è½½æ’ä»¶æ—¶è°ƒç”¨çš„åˆå§‹åŒ–å‡½æ•°"""
    await bot.add_cog(RSS(bot))
